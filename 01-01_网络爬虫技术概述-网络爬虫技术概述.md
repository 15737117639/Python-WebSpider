# 1 网络爬虫技术概述

## 1.1 网络爬虫技术概述

网络爬虫（又被称位网页蜘蛛，网络机器人），是一种按照一定的规则，自动地抓取互联网数据的计算机程序。    
编写网络爬虫程序主要涉及到的技术有：网络通信技术、多线程并发技术、数据交换技术、HTML等WEB前端技术、数据分析技术和数据存储技术。

### 1.1.1 网络通信技术

网络爬虫程序首先要通过网络通信技术访问互联网资源，这些资源通过URL指定，基于HTTP和HTTPS协议。  
具体而言在Python中可以通过urllib库访问互联网资源。  

### 1.1.2 多线程技术

一些为搜索引擎抓取数据的爬虫，需要24小时不停地工作，而且数据量非常巨大，为提高效率这些爬虫往往通过多个线程并发执行的，这就需要使用多线程并发技术。  
有些爬虫只是访问专门的网站，定时抓取特定数据，例如股票数据是定时更新的，也可以通过多线程技术实现，主要是使用多线程休眠特性，而不是它的并发特性。  
可以通过一个子线程根据特定时间执行爬虫程序，然后休眠，然后再执行爬虫程序，这样周而复始。

### 1.1.3 数据交换技术

从互联网获得的资源可能是规范的xml、json等数据格式，这些数据可以通过数据交换技术进行解析。

### 1.1.4 Web前端技术  

有时从互联网获得的资源并不是规范的XML、JSON等数据格式，而是HTML、CSS和JavaScript等数据，这些数据在浏览器中会显示出漂亮的网页，这就是Web前端技术。
在网络爬虫抓取HTML代码时，开发人员需要知道你所需要的数据裹挟在哪些HTML标签中，要想找到这些数据，可以使用一些浏览器中的Web开发工具。  
推荐使用Chrome或Firefox浏览器，因为这两个浏览器都自带了Web开发工具箱。  
Chrome浏览器可以通过菜单“更多工具”——>“开发者工具”打开。



Firefox浏览器可以通过菜单“Web开发者”——>“切换工具箱”。


  
可以通过快捷方式打开，在Windows平台下两个浏览器打开Web工具箱都是相同的快捷按键Ctrl+Shift+i。

### 1.1.5 数据分析技术  

作为网络爬虫的开发人员，需要分析HTML代码，抽丝剥茧找到需要的数据，这项工作比较繁琐，而且没有统一的规范。  
所需要技术主要是字符串处理和正则表达式等技术。  
Html代码的分析也可以借助第三方库，如BeautifulSoup等。  

### 1.1.6 数据存储技术  

数据分析完成需要保存起来，最理想的数据保存场所是数据库，由于数据是关联的关系型数据库，如Oracle、SQL Server、MySQL和SQLite等。    
少量数据也可以保存到文件中，这些文件应该是结构化的文档，采用XML、JSON和CSV等数据交换格式。  
